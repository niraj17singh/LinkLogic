{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac349d71-6459-4ffb-adfd-ee5bb5c02bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import eval\n",
    "import utils as ut\n",
    "import plot\n",
    "\n",
    "pd.options.mode.chained_assignment = None # turns off pandas SettingWithCopyWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef6872-e370-4b16-b61a-493842426661",
   "metadata": {},
   "source": [
    "### Run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4721f4-ef25-43d7-904b-9ea349f11811",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_results = False\n",
    "kthresh = 10\n",
    "score_column = f'top{kthresh} path score'\n",
    "path_column = 'path category'\n",
    "category_column = 'category'\n",
    "k_range = list(range(1, 11))\n",
    "limit_k = True\n",
    "figure_dir = '../../figures/submission_june_21/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa05579b-c3e0-494e-9965-d18dfe82674e",
   "metadata": {},
   "source": [
    "### Load benchmark and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a67b2eeb-fcdf-4287-bc9c-673754b2e190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded benchmark with 6260 triples\n"
     ]
    }
   ],
   "source": [
    "# load benchmark\n",
    "with open('../../data/commonsense_benchmark/v5/commonsense_benchmark_all.json', 'r') as f:\n",
    "    benchmark = json.load(f)\n",
    "    \n",
    "print(f'Loaded benchmark with {len(benchmark)} triples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3a843e-62ad-4244-aab6-1b2f6c2a60fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results for experiment sibling false, child true\n",
      "Loading results for experiment sibling false, child false\n",
      "Loading results for experiment sibling true, child true\n",
      "Loading results for experiment sibling true, child false\n"
     ]
    }
   ],
   "source": [
    "# load explanations\n",
    "results_dir = '../../explanations/linklogic/full_parents_benchmark/'\n",
    "experiments = {'sibling false, child true': ['fb13', 'True'],\n",
    "              'sibling false, child false': ['fb13', 'False'],\n",
    "              'sibling true, child true': ['fb14', 'True'],\n",
    "              'sibling true, child false': ['fb14', 'False']}\n",
    "\n",
    "results = dict()\n",
    "for experiment, strings in experiments.items():\n",
    "    print(f'Loading results for experiment {experiment}')\n",
    "    sibling = strings[0]\n",
    "    child = strings[1]\n",
    "    with open(f'{results_dir}/{sibling}_child_{child}.pickle', 'rb') as f:\n",
    "        results[experiment] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c07d38-675e-4a9c-9664-fd215e806c42",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb41b85a-5850-4b26-a8e0-b24d4e9e23cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6260/6260 [10:35<00:00,  9.84it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "feature_df_list = []\n",
    "\n",
    "for i, bmk in tqdm(enumerate(benchmark), total=len(benchmark)):\n",
    "\n",
    "    assert bmk['category'] == 'parents'\n",
    "    #assert len(bmk['entity_names']['siblings']) == 1\n",
    "\n",
    "    triple = bmk['query_triple']\n",
    "    s_triple = ut.stringify_path(triple)\n",
    "\n",
    "    bmk_df = eval.extract_bmk_paths_as_df(bmk, ctg_column=category_column)\n",
    "\n",
    "    for experiment in experiments.keys():\n",
    "\n",
    "        res = eval.get_results_for_query_triple(results[experiment], triple)\n",
    "        if not res:\n",
    "            continue\n",
    "            \n",
    "        feature_df = eval.extract_feature_df_from_results(res['linklogic_features'], bmk_df=bmk_df, names=bmk['entity_names'], kthresh=kthresh,\n",
    "                                                          experiment=experiment, query_triple=s_triple)\n",
    "        num_true_candidates = feature_df['label'].sum()\n",
    "        if num_true_candidates == 0:\n",
    "            continue\n",
    "\n",
    "        feature_df_list.append(feature_df)\n",
    "        \n",
    "        y_true = [feature_df['label']]\n",
    "        y_true_weighted = [feature_df['bmk confidence']]\n",
    "        y_heuristic = [feature_df['baseline path score']]\n",
    "        y_linklogic = [feature_df['coefficient']]\n",
    "        y_random = [feature_df['random']]\n",
    "        \n",
    "        if limit_k:\n",
    "            ks = eval.filter_k_range(k_range, feature_df['coefficient'])\n",
    "        else:\n",
    "            ks = k_range\n",
    "\n",
    "        metrics.append({'experiment': experiment,\n",
    "                        'ndcg: heuristic': eval.ndcg_score_range(y_true, y_heuristic, ks),\n",
    "                        'ndcg: linklogic': eval.ndcg_score_range(y_true, y_linklogic, ks),\n",
    "                        'ndcg: random': eval.ndcg_score_range(y_true, y_random, ks),\n",
    "                        \n",
    "                        'wndcg: heuristic': eval.ndcg_score_range(y_true_weighted, y_heuristic, ks),\n",
    "                        'wndcg: linklogic': eval.ndcg_score_range(y_true_weighted, y_linklogic, ks),\n",
    "                        'wndcg: random': eval.ndcg_score_range(y_true_weighted, y_random, ks),\n",
    "            \n",
    "                        'num true': num_true_candidates,\n",
    "                        'query triple': s_triple,\n",
    "                        'kge score': float(res['query_triple_kge_score']),\n",
    "                        'fidelity': res['linklogic_metrics']['test_acc']})\n",
    "\n",
    "        if plot_individual_results:\n",
    "            fig = px.scatter(feature_df, x='baseline path score', y='coefficient', color='label',\n",
    "                             hover_data=[\"path\"], title=f'features: {s_triple}')\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c3ccdc-af37-4aa6-aa90-73b7b7ae120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pd.DataFrame(metrics)\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159a645-944d-4797-be8c-44828f680f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figure_dir = '../../figures/submission_june_21/'\n",
    "M.to_csv(f'{figure_dir}/metrics_parents_benchmark_all.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48c3b9-5f96-4201-a947-bb796a7fecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic = 'Path score heuristic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f544878-38a8-42fc-bb26-653269553f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d3a5b-822e-40bc-b783-a8643bcee1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#sns.scatterplot(data=M, x='ndcg: linklogic', y='wndcg: linklogic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a8f5d9-6d2f-411a-b49a-7cda39b9fc18",
   "metadata": {},
   "source": [
    "### Summary metrics: NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e3e65-b91c-4914-8b4c-d220f8da2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_metric(M, experiments=['sibling false, child false'], metric='wndcg', filename=None):\n",
    "    rows = []\n",
    "    for i, row in M.iterrows():\n",
    "\n",
    "        max_k = len(row[f'{metric}: random'])\n",
    "        ks = k_range[:max_k]\n",
    "\n",
    "        if row['experiment'] in experiments:\n",
    "            for k in ks:\n",
    "                rows.append({\n",
    "                    'k': str(k),\n",
    "                    'query triple': row['query triple'],\n",
    "                    'experiment': row['experiment'],\n",
    "                    heuristic: row[f'{metric}: heuristic'][k-1],\n",
    "                    'linklogic': row[f'{metric}: linklogic'][k-1]\n",
    "                })\n",
    "    m = pd.DataFrame(rows).melt(id_vars=['k', 'query triple', 'experiment'])\n",
    "\n",
    "    m = m[m['k'].isin(['1', '2', '3', '4', '5', '6', '7'])]\n",
    "\n",
    "    pal = plot.get_categorical_palette()\n",
    "    palette = {'linklogic': pal['linklogic'], heuristic: pal['Heuristic95']}\n",
    "    plt.figure(figsize=(5,4))\n",
    "    g = sns.lineplot(data=m, x='k', y='value', hue='variable', hue_order=palette.keys(), palette=palette)\n",
    "    _ = g.set(ylabel='NDCG@K')\n",
    "    _ = g.legend(title='')\n",
    "    \n",
    "    if filename is not None:\n",
    "        g.get_figure().savefig(filename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b15335f-9c6b-423b-9183-edcd1d7af187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57460d0e-9d68-44ec-9aae-e12031198e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance_metric(M, experiments=['sibling false, child false'], metric='wndcg', filename=f'{figure_dir}NDCG.{plot.figtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c19149c-dae5-44bb-bbc9-1d0c31fdb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "metric = 'wndcg'\n",
    "for i, row in M.iterrows():\n",
    "    \n",
    "    max_k = len(row[f'{metric}: random'])\n",
    "    ks = k_range[:max_k]\n",
    "        \n",
    "    for k in ks:\n",
    "        rows.append({\n",
    "            'k': str(k),\n",
    "            'query triple': row['query triple'],\n",
    "            'experiment': row['experiment'],\n",
    "            heuristic: row[f'{metric}: heuristic'][k-1],\n",
    "            'linklogic': row[f'{metric}: linklogic'][k-1]\n",
    "        })\n",
    "m = pd.DataFrame(rows).melt(id_vars=['k', 'query triple', 'experiment'])\n",
    "\n",
    "m = m[m['k'].isin(['1', '2', '3', '4', '5', '6', '7'])]\n",
    "\n",
    "pal = plot.get_categorical_palette()\n",
    "palette = {'linklogic': pal['linklogic'], heuristic: pal['Heuristic95']}\n",
    "plt.figure(figsize=(5,4))\n",
    "g = sns.lineplot(data=m, x='k', y='value', hue='variable', hue_order=palette.keys(), palette=palette)\n",
    "_ = g.set(ylabel='NDCG@K')\n",
    "_ = g.legend(title='')\n",
    "#g.get_figure().savefig(f'{figure_dir}NDCG.{plot.figtype}', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4bfbb4-7160-4d20-b456-34c68f458430",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pd.DataFrame(metrics)  \n",
    "rows = []\n",
    "metric = 'wndcg'\n",
    "for i, row in M.iterrows():\n",
    "    \n",
    "    max_k = len(row[f'{metric}: random'])\n",
    "    ks = k_range[:max_k]\n",
    "        \n",
    "    for k in ks:\n",
    "        rows.append({\n",
    "            'k': str(k),\n",
    "            'query triple': row['query triple'],\n",
    "            'experiment': row['experiment'],\n",
    "            heuristic: row[f'{metric}: heuristic'][k-1],\n",
    "            'linklogic': row[f'{metric}: linklogic'][k-1]\n",
    "        })\n",
    "m = pd.DataFrame(rows).melt(id_vars=['k', 'query triple', 'experiment'])\n",
    "m.rename(columns={'value': 'NDCG@K', 'variable': 'Method'}, inplace=True)\n",
    "\n",
    "m = m[m['k'].isin(['1', '2', '3', '4', '5', '6', '7'])]\n",
    "\n",
    "pal = plot.get_categorical_palette()\n",
    "palette = {'linklogic': pal['linklogic'], heuristic: pal['Heuristic95']}\n",
    "\n",
    "sns.set(font_scale=1.2)\n",
    "g = sns.relplot(data=m, x=\"k\", y=\"NDCG@K\", hue=\"Method\", col=\"experiment\", kind='line')\n",
    "\n",
    "g.savefig(f'{figure_dir}NDCG_all.{plot.figtype}', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7e49da-2453-4a5c-9fd5-43a412d21000",
   "metadata": {},
   "source": [
    "# Path Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e447eb-131e-4df6-873e-31920e3909b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata = pd.concat(feature_df_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd455d85-c56a-43de-9124-1bd769dca459",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede81cd6-91bd-4b44-87a2-96fa165d4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#palette = plot.get_categorical_palette(plot=False)\n",
    "xcol = 'coefficient'\n",
    "min_count = 150\n",
    "# palette = {'sibling false, child false':palette['col3'],\n",
    "#   'sibling false, child true': palette['col6'],\n",
    "#   'sibling true, child false': palette['col2'],\n",
    "#   'sibling true, child true': palette['col4']}\n",
    "palette = {'sibling false, child false':'tab:red',\n",
    " 'sibling false, child true': 'tab:olive',\n",
    " 'sibling true, child false': 'mediumorchid',\n",
    " 'sibling true, child true': 'tab:cyan'}\n",
    "\n",
    "# query_triples = random.sample(set(fdata.query_triple), 5)\n",
    "\n",
    "#for experiment in experiments.keys():\n",
    "    \n",
    "#     plot.incidents_per_path_category(fdata, experiments=[experiment], min_count=min_count, palette=palette, score_column='coefficient', \n",
    "#                                      path_column=path_column, filename=f'{figure_dir}/linklogic: {experiment}.png')\n",
    "\n",
    "#     plot.incidents_per_path_category(fdata, experiments=[experiment], min_count=min_count, palette=palette, score_column=f'top{kthresh} path score', \n",
    "#                                      path_column=path_column, filename=f'{figure_dir}/Heuristic: {experiment}.png')\n",
    "    \n",
    "    \n",
    "   # for triple in query_triples:\n",
    "   #     plot.scores_per_path_category(fdata, score_column='normalized coefficient', title=f'Path Logic {triple}', experiments=[experiment],\n",
    "   #                                   filename=f'{figure_dir}linklogic scores {experiment} {triple}.png', min_val = 0.01, palette=palette, query_triple=triple)\n",
    "\n",
    "   #     plot.scores_per_path_category(fdata, score_column=f'top{kthresh} path score', title=f'Heuristic Scoring, top {kthresh}, {triple}', experiments=[experiment],\n",
    "   #                                   filename=f'{figure_dir}Heuristic scores {experiment} {triple}.png', min_val=0.1, palette=palette, query_triple=triple)\n",
    "\n",
    "plot.incidents_per_path_category(fdata, experiments=['sibling false, child true', 'sibling false, child false'], min_count=min_count,\n",
    "                                 palette=palette, score_column=score_column, path_column=path_column, filename=f'{figure_dir}Exp1_2_NoSibling_RemoveChild.png')\n",
    "plot.incidents_per_path_category(fdata, experiments=['sibling true, child true', 'sibling true, child false'], min_count=min_count,\n",
    "                                 palette=palette, score_column=score_column, path_column=path_column, filename=f'{figure_dir}Exp3_WithSibling_RemoveChild.png')\n",
    "plot.incidents_per_path_category(fdata, experiments=['sibling false, child false', 'sibling true, child false'], min_count=min_count,\n",
    "                                 palette=palette, score_column=score_column, path_column=path_column, filename=f'{figure_dir}Exp2_3_NoChild_AddSibling.png')\n",
    "plot.incidents_per_path_category(fdata, experiments=['sibling false, child true', 'sibling true, child true'], min_count=min_count,\n",
    "                                 palette=palette, score_column=score_column, path_column=path_column, filename=f'{figure_dir}Exp1_3_WithChild_AddSibling.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e3c02-573a-4ec8-8536-19e844befb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata.to_csv(f'{figure_dir}/all_feature_data_for_parents_path_reports.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58502d-a82c-4f20-97ba-3ebc6a07a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P = M[M.experiment == 'sibling false, child false']\n",
    "#P.to_csv('sibling_false_child_false_query_triple_metrics.tsv',sep='\\t', index=None)\n",
    "# rows = []\n",
    "# for i, row in P.iterrows():\n",
    "#     row_metrics = row['ndcg: linklogic']\n",
    "#     if len(row_metrics) >= 5:        \n",
    "#          rows.append({\n",
    "#              'query_triple': row['query triple'],\n",
    "#              'ndcg': row_metrics[4],\n",
    "#              'fidelity': row['fidelity']\n",
    "#          })\n",
    "# triple_metrics = pd.DataFrame(rows)\n",
    "# triple_metrics.to_csv('triple_metrics.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
