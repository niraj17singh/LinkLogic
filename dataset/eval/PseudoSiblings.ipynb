{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "furnished-allowance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABECAYAAAAiJuZQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAB6ElEQVR4nO3YMUpcURiG4TPeEUdIgqQIBCxSugMXEMg+0gimsnIRKUJq63TuQJBAdpAukMZCSDs4goK5nhRiGaY635Hr87T3Ft/lh5dhZrXWWgCI2Og9AOA5EV2AINEFCBJdgCDRBQgSXYCg+boXvp0uy+r6PrEl7vDj63J58rn3jGZ2D47Ll9/fe89o4tP4syz2jsrtr6+9pzSx2DsqF+dnvWc08+79h/Lj8k/vGU1sDUPZf/vmv8/XRnd1fV+uVtOMbimljFfL3hOaWt7d9J7QRB0f7lbvpnu/vzfTvN2j23HsPaELfy8ABIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgTN173w8sW0uzy82uk9oamdze3eE5qYbTzcbbY53fvNt6d5u0eLYeg9oYmtNd81q7XW0BaAZ2/aP2MBnhjRBQgSXYAg0QUIEl2AINEFCPoHEWY3dGGBOMwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle5 as pickle\n",
    "import json\n",
    "from sklearn.metrics import ndcg_score\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "sns.set(font_scale=1.5)\n",
    "pd.set_option('display.max_rows', 999)\n",
    "\n",
    "colors = sns.color_palette(\"Spectral\", 10)\n",
    "pal = [colors[9],colors[1], colors[7],colors[0],colors[3],colors[8],colors[2]]\n",
    "pal_unnorm = [[136, 145, 235], [224, 139, 121], [125, 213, 181],\n",
    "        [246, 210, 127], [219, 179, 176], [185, 224, 227], ]\n",
    "pal = [[a/255,b/255,c/255] for a,b,c in pal_unnorm]\n",
    "sns.palplot(pal)\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "express-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data, condition, explanation_key):\n",
    "    records = []\n",
    "    for query in data:\n",
    "        explanations = query[explanation_key]\n",
    "        for explanation in explanations:\n",
    "            ex_h1, ex_r1, ex_t1, ex_r2, ex_t2 = (np.nan,np.nan,np.nan,np.nan,np.nan)\n",
    "            ex_h1 =  explanation['path'][0]\n",
    "            ex_r1 =  explanation['path'][1]\n",
    "            ex_t1 =  explanation['path'][2]\n",
    "            \n",
    "            if len(explanation['path'])>3:\n",
    "                path_type = 'two_hop'\n",
    "                ex_r2 =  explanation['path'][3]\n",
    "                ex_t2 =  explanation['path'][4]\n",
    "                hops = [(ex_h1, ex_r1, ex_t1), (ex_t1, ex_r2,ex_t2)]\n",
    "            else:\n",
    "                path_type = 'one_hop'\n",
    "                hops = [(ex_h1, ex_r1, ex_t1)]\n",
    "            \n",
    "            if 'coef' in explanation:\n",
    "                coef = explanation['coef']\n",
    "                one_hop_score = explanation['kge_score']['1st_hop_kge_score']\n",
    "                path_score = explanation['kge_score']['path_score']\n",
    "            else:\n",
    "                coef, one_hop_score, path_score = (np.nan, np.nan, np.nan)\n",
    "            if 'split' in explanation:\n",
    "                split = explanation['split']\n",
    "            else:\n",
    "                split = np.nan\n",
    "            \n",
    "            for index, hop in enumerate(hops):\n",
    "                records.append({\n",
    "                        'cond':condition,\n",
    "                        'query_string': query['query_triple'][0] + '_has_parents_' + query['query_triple'][2],\n",
    "                        'q_head': query['query_triple'][0],\n",
    "                        'q_rel': query['query_triple'][1],\n",
    "                        'q_tail': query['query_triple'][2],\n",
    "                        'path_type': path_type,\n",
    "                        'hop': index+1,\n",
    "                        'ex_head': hop[0],\n",
    "                        'ex_rel': hop[1],\n",
    "                        'ex_tail': hop[2],\n",
    "                        'coef':coef,\n",
    "                        'first_hop_score': one_hop_score,\n",
    "                        'path_score': path_score,                  \n",
    "                        'split':split})\n",
    "    return records\n",
    "\n",
    "def pickle_to_data(experiment_path, conditions, experiments):\n",
    "    results = {}\n",
    "    results['no_sib'] = {}\n",
    "    results['with_sib'] = {}\n",
    "    for condition in conditions:\n",
    "        for experiment in experiments:\n",
    "            with open(f'{experiment_path}{experiment}_{condition}.pickle', 'rb') as f:\n",
    "                results[experiment][condition] = pickle.load(f)\n",
    "    records = []\n",
    "    for expt in experiments:\n",
    "        for cond in conditions:\n",
    "            records.extend(parse_data(results[expt][cond], expt + '_' + cond, 'linklogic_explanations'))\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def find_sibling_links_not_in_fb13(df):\n",
    "    records = []\n",
    "    for index, row in df[(df.ex_head==df.q_head) | (df.ex_tail==df.q_head)].iterrows():\n",
    "        if row['link_exists']==0:\n",
    "            if (row['ex_head']==row['q_head']) and (row['ex_tail'] in true_siblings[row['q_head']]):\n",
    "                records.append(row.to_dict())\n",
    "            elif (row['ex_tail']==row['q_head']) and (row['ex_head'] in true_siblings[row['q_head']]):\n",
    "                records.append(row.to_dict())\n",
    "    \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def find_sibling_links_not_in_fb13_long(df, fb_data):\n",
    "    records = []\n",
    "    for index, row in df[(df.ex_head==df.q_head) | (df.ex_tail==df.q_head)].iterrows():\n",
    "        fb_sub = fb_data[(fb_data.e1==row['q_head']) | (fb_data.e2==row['q_head'])]\n",
    "        if (row['ex_head']==row['q_head']) and (row['ex_rel'] not in fb_sub.r) and (row['ex_tail'] in true_siblings[row['q_head']]):\n",
    "            records.append(row.to_dict())\n",
    "        elif (row['ex_tail']==row['q_head']) and (row['ex_rel'] not in fb_sub.r) and (row['ex_head'] in true_siblings[row['q_head']]):\n",
    "            records.append(row.to_dict())\n",
    "    \n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interesting-harris",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../results/Exp4/results/4a_100.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3d55c8fca533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../results/Exp4/results/4a_100.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mnonsensical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../results/Exp4/results/4d_100.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrue_triples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../results/Exp4/results/4a_100.pickle'"
     ]
    }
   ],
   "source": [
    "with open('../../results/Exp4/results/4a_100.pickle', 'rb') as f:\n",
    "    nonsensical = pickle.load(f)\n",
    "    \n",
    "with open('../../results/Exp4/results/4d_100.pickle', 'rb') as f:\n",
    "    true_triples = pickle.load(f)\n",
    "    \n",
    "with open('../../results/Exp4/results/4b_100.pickle', 'rb') as f:\n",
    "    false_triples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsensical_r2 = [a['linklogic_metrics']['test_acc'] for a in nonsensical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([a for a in nonsensical_r2 if a<0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_r2 = [a['linklogic_metrics']['test_acc'] for a in true_triples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(true_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(true_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(a['linklogic_explanations']) for a in true_triples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exps = []\n",
    "for a in true_triples:\n",
    "    num_exps = 0\n",
    "    for b in a['linklogic_explanations']:\n",
    "        if b['kge_score']['path_score']>2.9957:\n",
    "            num_exps+=1\n",
    "    all_exps.append(num_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(all_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsensical_r2 = [a['linklogic_metrics']['test_acc'] for a in nonsensical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(nonsensical_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_r2 = [a['linklogic_metrics']['test_acc'] for a in false_triples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(false_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-minnesota",
   "metadata": {},
   "source": [
    "### Get that benchmark and siblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/commonsense_benchmark_for_analysis.json', 'r') as f:\n",
    "    benchmark = json.load(f)\n",
    "with open('../../data/siblings.json', 'r') as f:\n",
    "    true_siblings = json.load(f)\n",
    "\n",
    "name_type = pd.read_csv('../../data/entity_names_to_types.csv')\n",
    "\n",
    "b_df = pd.DataFrame(parse_data(benchmark, 'benchmark','explanatory_paths'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-demographic",
   "metadata": {},
   "source": [
    "### Get that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for split in ['train','valid','test']:   \n",
    "    temp = pd.read_csv(f'../../data/fb13_resplit/{split}.txt',sep='\\t',names=['e1','r','e2'])\n",
    "    temp['split']=split\n",
    "    df_list.append(temp)\n",
    "fb_13 = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_13.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-court",
   "metadata": {},
   "source": [
    "### Get those results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['child_true','child_false']\n",
    "experiments = ['no_sib','with_sib']\n",
    "\n",
    "cond_order = ['no_sib_child_true','no_sib_child_false','with_sib_child_true','with_sib_child_false']\n",
    "\n",
    "df_split = pickle_to_data('../../results/rachel_results/', conditions, experiments)\n",
    "df_full = pickle_to_data('../../results/full_results/', conditions, experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_emb_13 = np.load('../../results/fb_13/relation_embedding.npy')\n",
    "rel_id_13 = pd.read_csv('../../results/fb_13/relation2id.txt', sep='\\t', names=['rel','idx'])\n",
    "rel_emb_14 = np.load('../../results/fb_14/relation_embedding.npy')\n",
    "rel_id_14 = pd.read_csv('../../results/fb_14/relation2id.txt', sep='\\t',names=['rel','idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_id_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_split = df_split[df_split.q_head.isin(true_siblings)]\n",
    "df_full = df_full[df_full.q_head.isin(true_siblings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full\n",
    "df = df.merge(fb_13, left_on=['ex_head','ex_rel','ex_tail'], right_on=['e1','r','e2'], how='left')\n",
    "df.loc[~pd.isnull(df.e1), 'link_exists']=1\n",
    "df.drop(columns=['split_x','e1','r','e2'], inplace=True)\n",
    "df.rename(columns={'split_y':'split'}, inplace=True)\n",
    "df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-testament",
   "metadata": {},
   "source": [
    "##### Question: what are the relations involved when predicting the parent over conditions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "ax = sns.barplot(x = \"ex_rel\", y=\"q_head\", hue=\"cond\",palette=pal,\n",
    "    data = df[df.path_type=='one_hop'].groupby(['cond','ex_rel']).count().sort_values(by=['cond']).sort_values(\n",
    "        by=['coef'], ascending=False).reset_index(), hue_order = cond_order)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45, ha='right')\n",
    "ax.set_ylabel('Prevalance (# incidents)')\n",
    "ax.set_xlabel('Relation')\n",
    "plt.legend(title='')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "\n",
    "for idx, hop_num in enumerate([1,2]):\n",
    "    plt.subplot(1,2,idx+1)\n",
    "    ax = sns.barplot(x ='ex_rel', y=\"q_head\", hue=\"cond\",palette=pal,\n",
    "        data = df[(df.path_type=='two_hop') & (df.hop==hop_num)].groupby(['cond', 'ex_rel']).count().sort_values(by=['cond']).sort_values(\n",
    "            by=['coef'], ascending=False).reset_index(), hue_order = cond_order)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation=45, ha='right')\n",
    "    ax.set_ylabel('Prevalance (# incidents)')\n",
    "    ax.set_xlabel('Relation')\n",
    "    plt.legend(title='')\n",
    "    ax.set_title(f\"Hop {hop_num}\")\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "ax = sns.barplot(x = \"ex_rel\", y=\"q_head\", hue=\"cond\",palette=pal,\n",
    "    data = df[(df.path_type=='one_hop') & \n",
    "              (df.cond.isin(['no_sib_child_false','with_sib_child_false']))].groupby(\n",
    "        ['cond','ex_rel']).count().sort_values(by=['cond']).sort_values(\n",
    "        by=['coef'], ascending=False).reset_index(), hue_order = [cond_order[1],cond_order[3]])\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45, ha='right')\n",
    "ax.set_ylabel('Prevalance (# incidents)')\n",
    "ax.set_xlabel('Relation')\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-pregnancy",
   "metadata": {},
   "source": [
    "##### What % of new hops that contain a lone child without completing triangle thats then actually a sibling of main child (query= [C1]-parents-[P1] and [P1]-children-[C2] shows up as an explanation, where [C1]-sibling-[C2])?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for qq in list(df[df.cond.isin(['no_sib_child_false'])].query_string.unique()):\n",
    "    no_sib = df[(df.query_string==qq) & \n",
    "    (df.cond=='no_sib_child_false')].sort_values(by='coef', ascending=False).reset_index(drop=True)\n",
    "    with_sib = df[(df.query_string==qq) & \n",
    "    (df.cond=='with_sib_child_false')].sort_values(by='coef', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    if not with_sib.empty:\n",
    "        if no_sib.loc[0,'ex_rel']=='children':\n",
    "            sib = no_sib.loc[0,'ex_tail']\n",
    "\n",
    "        pred_bool = (with_sib.loc[0,'ex_head']==no_sib.loc[0,'ex_head'] and \n",
    "                 with_sib.loc[0,'ex_rel']==no_sib.loc[0,'ex_rel'] and\n",
    "                 with_sib.loc[0,'ex_tail']==no_sib.loc[0,'ex_tail'])\n",
    "\n",
    "        sib_bool = (with_sib.loc[1,'ex_head']== with_sib.loc[1,'q_head'] and\n",
    "                 with_sib.loc[1,'ex_rel']=='sibling' and\n",
    "                 with_sib.loc[1,'ex_tail']==sib)\n",
    "\n",
    "\n",
    "        records.append({'query_string': qq,\n",
    "         'same_top_pred': 1 if pred_bool else 0,\n",
    "         'filled_in_sib': 1 if sib_bool else 0,\n",
    "         'no_sib_coef': no_sib.loc[0,'coef'],\n",
    "         'with_sib_coef': with_sib.loc[0,'coef'],\n",
    "         'sib_coef': with_sib.loc[1,'coef']})\n",
    "\n",
    "             \n",
    "sib_switch = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-raise",
   "metadata": {},
   "source": [
    "## Find pseudo-sibling relations in the split and full results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo_split = find_sibling_links_not_in_fb13(df_split[df_split.cond.isin(['no_sib_child_false', 'no_sib_child_true'])],\n",
    "#                                         fb_13)\n",
    "\n",
    "pseudo_full = find_sibling_links_not_in_fb13(df[df.cond.isin(['no_sib_child_false'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "sib_equiv = df_full[(df_full.cond.isin(['with_sib_child_false'])) & (df_full.query_string.isin(pseudo_full.query_string)) & \n",
    "                                                       (df_full.ex_rel=='sibling')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for index, row in pseudo_full.iterrows():\n",
    "    new_edge = sib_equiv[(sib_equiv.ex_head == row['ex_head']) & (sib_equiv.ex_tail == row['ex_tail'])]\n",
    "    if not new_edge.empty:\n",
    "        row['run_type']='FB13'\n",
    "        row['ex_string']=row['ex_head'] + '_' + row['ex_rel'] + '_' + row['ex_tail'] \n",
    "        new_row = new_edge.to_dict(orient='records')[0]\n",
    "        new_row['run_type']='FB14'\n",
    "\n",
    "        \n",
    "        records.append(row.to_dict())\n",
    "        records.append(new_row)\n",
    "pseudo_sib = pd.DataFrame(records)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "def add_stat_star(p_val):\n",
    "    anot = \"ns\"\n",
    "    if p_val < 0.001:\n",
    "        anot = \"***\"\n",
    "    elif p_val < 0.01:\n",
    "        anot = \"**\"\n",
    "    elif p_val < 0.05:\n",
    "        anot = \"*\"\n",
    "        \n",
    "    x1, x2 = 0, 1 \n",
    "    y, h, col = 0.8, 0.02, 'k'\n",
    "    plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "    plt.text((x1+x2)*.5, y+h, anot, ha='center', va='bottom', color=col, fontsize=40)\n",
    "\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "ax = sns.scatterplot(x=rel_emb_13[rel_id_13.loc[rel_id_13['rel']=='children','idx'].values[0]][:200],\n",
    "               y=rel_emb_13[rel_id_13.loc[rel_id_13['rel']=='spouse','idx'].values[0]][:200], \n",
    "                     s=100, edgecolor = 'black', color=pal[0], label='Real part')\n",
    "sns.scatterplot(x=rel_emb_13[rel_id_13.loc[rel_id_13['rel']=='children','idx'].values[0]][200:],\n",
    "               y=rel_emb_13[rel_id_13.loc[rel_id_13['rel']=='spouse','idx'].values[0]][200:],\n",
    "                s=100,  edgecolor = 'black', color=pal[1], label='Img. part')\n",
    "ax.set_xlim([-0.7, 0.7])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_xlabel('FB13 children')\n",
    "ax.set_ylabel('FB13 spouse')\n",
    "plt.legend(loc='lower right')\n",
    "plt.text(-1.2, 0.9,\"A\", color='black', fontweight='bold', fontsize=35)\n",
    "\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "ax = sns.scatterplot(x=rel_emb_14[rel_id_14.loc[rel_id_14['rel']=='children','idx'].values[0]][:200],\n",
    "               y=rel_emb_14[rel_id_14.loc[rel_id_14['rel']=='sibling','idx'].values[0]][:200],\n",
    "                s=100, edgecolor = 'black', color=pal[3],label='Sibling-Child')\n",
    "\n",
    "\n",
    "ax = sns.scatterplot(x=rel_emb_14[rel_id_14.loc[rel_id_14['rel']=='children','idx'].values[0]][:200],\n",
    "               y=rel_emb_14[rel_id_14.loc[rel_id_14['rel']=='spouse','idx'].values[0]][:200],\n",
    "                s=100, edgecolor = 'black', color=pal[2],label='Spouse-Child')\n",
    "\n",
    "ax.set_xlim([-0.7, 0.7])\n",
    "ax.set_ylim([-1, 1])\n",
    "plt.legend()\n",
    "ax.set_xlabel('FB14 children')\n",
    "ax.set_ylabel('FB14 sibling')\n",
    "plt.legend(loc='lower right')\n",
    "plt.text(-1.2, 0.9,\"B\", color='black', fontweight='bold', fontsize=35)\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "ax = sns.scatterplot(x=rel_emb_14[rel_id_14.loc[rel_id_14['rel']=='spouse','idx'].values[0]][:200],\n",
    "               y=rel_emb_14[rel_id_14.loc[rel_id_14['rel']=='sibling','idx'].values[0]][:200],\n",
    "                s=100, edgecolor = 'black', color=pal[0],label='Real part')\n",
    "sns.scatterplot(x=rel_emb_14[rel_id_14.loc[rel_id_14['rel']=='spouse','idx'].values[0]][200:],\n",
    "               y=rel_emb_14[rel_id_14.loc[rel_id_14['rel']=='sibling','idx'].values[0]][200:], \n",
    "                s=100, edgecolor = 'black', color=pal[1], label='Img. part')\n",
    "ax.set_xlim([-0.7, 0.7])\n",
    "ax.set_ylim([-1, 1])\n",
    "plt.legend()\n",
    "ax.set_xlabel('FB14 spouse')\n",
    "ax.set_ylabel('FB14 sibling')\n",
    "plt.legend(loc='lower right')\n",
    "plt.text(-1.2, 0.9,\"C\", color='black', fontweight='bold', fontsize=35)\n",
    "#plt.legend(loc=(1.05,0))\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "ax = sns.boxplot(x=\"run_type\",y=\"coef\", data=pseudo_sib, palette =[pal[4],pal[5]],showfliers=False)\n",
    "tests = stats.mannwhitneyu(pseudo_sib[pseudo_sib.run_type=='FB13'].coef, pseudo_sib[pseudo_sib.run_type=='FB14'].coef)\n",
    "add_stat_star(tests.pvalue)\n",
    "sns.stripplot(x=\"run_type\",y=\"coef\", data=pseudo_sib, color='grey',s=15)\n",
    "ax.set_xticklabels([])\n",
    "sns.despine()\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylim([-0.1,1.1])\n",
    "ax.set_xticklabels(['FB13','FB14'])\n",
    "ax.set_ylabel('linklogic coefficient')\n",
    "plt.text(-1.2, 1.03,\"D\", color='black', fontweight='bold', fontsize=35)\n",
    "\n",
    "\n",
    "# plt.subplot(2,3,6)\n",
    "# ax = sns.boxplot(x=\"run_type\",y=\"path_score\", data=pseudo_sib, palette =[pal[4],pal[5]], showfliers=False)\n",
    "# tests = stats.mannwhitneyu(pseudo_sib[pseudo_sib.run_type=='FB13'].path_score, \n",
    "#                            pseudo_sib[pseudo_sib.run_type=='FB14'].path_score)\n",
    "# add_stat_star(tests.pvalue)\n",
    "\n",
    "# x1, x2 = 0, 1 \n",
    "# y, h, col = 4.1, 0.02, 'k'\n",
    "# plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "# plt.text((x1+x2)*.5, y+h, '**', ha='center', va='bottom', color=col, fontsize=40)\n",
    "\n",
    "#sns.stripplot(x=\"run_type\",y=\"path_score\", data=pseudo_sib, color='grey',s=15)\n",
    "\n",
    "# plt.legend(title='')\n",
    "# ax.set_ylim([1,5])\n",
    "# ax.set_xticklabels([])\n",
    "# #plt.legend(loc=(1.05,0))\n",
    "# ax.get_legend().remove()\n",
    "# ax.set_xticklabels(['FB13','FB14'])\n",
    "# sns.despine()\n",
    "# ax.set_xlabel('')\n",
    "# ax.set_ylabel('linklogic score')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../../paper_figures/Experiment_3.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(df[(df.ex_rel=='spouse') & (df.cond=='no_sib_child_false')].path_score.unique())\n",
    "sns.stripplot(df[(df.ex_rel=='spouse') & (df.cond=='with_sib_child_false')].path_score.unique(), color='red')\n",
    "sns.stripplot(df[(df.ex_rel=='sibling') & (df.cond=='with_sib_child_false')].path_score.unique(), color='yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[(df_full.cond=='no_sib_child_true') & (df_full.ex_rel=='children') & (df_full.path_type=='one_hop')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[(df_full.cond=='no_sib_child_true')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_used = []\n",
    "child_coef = []\n",
    "next_coef = []\n",
    "for query_string in tqdm(list(df_full[(df_full.cond=='no_sib_child_true')].query_string.unique())):\n",
    "    sub_df = df_full[(df_full.cond=='no_sib_child_true') & \n",
    "                     (df_full.query_string==query_string)].sort_values(by='coef', ascending=False).reset_index(drop=True)\n",
    "    if sub_df.loc[0,'ex_rel']=='children' and sub_df.loc[0,'path_type']=='one_hop':\n",
    "        child_used.append(1)\n",
    "        child_coef.append(sub_df.loc[0,'coef'])\n",
    "        if sub_df.shape[0]>1:\n",
    "            next_coef.append(sub_df.loc[1,'coef'])\n",
    "        else:\n",
    "            next_coef.append(0)\n",
    "    else:\n",
    "        child_used.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-victor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-gathering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-monthly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-fitting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
