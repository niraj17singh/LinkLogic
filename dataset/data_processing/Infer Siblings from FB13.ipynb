{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f74256-bbb5-4876-8b41-3b3664deb7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa0b156-83c9-499d-a5ae-29350c7929ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/fb13/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71c36b3-8bf1-416d-9add-a6e4837a5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup database connection\n",
    "driver = GraphDatabase.driver('bolt://localhost:7687', auth=('neo4j', 'fb13'))\n",
    "sess = driver.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03a17e7-ede3-411f-a7b6-34bdc588f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_to_df(res):\n",
    "    result_list = [record for record in res]\n",
    "    return pd.DataFrame(result_list, columns=res.keys())\n",
    "\n",
    "\n",
    "def split_triples(triples, fracs):\n",
    "    assert len(fracs) == 3\n",
    "    assert sum(fracs) == 1\n",
    "    \n",
    "    train, remainder = split_triples_into_two(triples, fracs[0])\n",
    "    valid, test = split_triples_into_two(remainder, fracs[1]/(fracs[1] + fracs[2]))\n",
    "    \n",
    "    return train, valid, test\n",
    "\n",
    "def split_triples_into_two(triples, frac):\n",
    "    group1 = triples.sample(frac=frac, random_state=42)\n",
    "    group2 = triples.drop(group1.index)\n",
    "    assert group1.shape[0] + group2.shape[0] == triples.shape[0]\n",
    "    return group1, group2\n",
    "\n",
    "# Note that we are using Graph instead of MultiDiGraph here since networkx does not support\n",
    "# computing connected components on a directed graph \n",
    "def construct_networkx_object(df_triples, df_entities):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # add nodes\n",
    "    print('adding nodes')\n",
    "    e_tuples = [(row['name'], {'id': row['id']}) for i, row in df_entities.iterrows()]\n",
    "    G.add_nodes_from(e_tuples)\n",
    "    \n",
    "    # add edges\n",
    "    print('adding edges')\n",
    "    for i, row in tqdm(df_triples.iterrows(), total=df_triples.shape[0]):\n",
    "        G.add_edge(row.e1, row.e2, relation=row.rel)\n",
    "        \n",
    "    assert nx.number_of_nodes(G) == df_entities.shape[0]\n",
    "        \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec334e2b-be03-4e28-879b-0d1ac1de98aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6666, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = '''\n",
    "MATCH (ch:Person)-[:parents]->(pa:Person)\n",
    "RETURN ch.name as child, pa.name as parent\n",
    "\n",
    "UNION\n",
    "\n",
    "MATCH (ch:Person)<-[:children]-(pa:Person)\n",
    "RETURN ch.name as child, pa.name as parent\n",
    "'''\n",
    "parents = res_to_df(sess.run(q))\n",
    "parents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78f97c1-f474-48ef-a04a-4366707dc08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child</th>\n",
       "      <th>parent</th>\n",
       "      <th>num_parents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a_k_faezul_huq</td>\n",
       "      <td>{a_k_fazlul_huq}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a_starker_leopold</td>\n",
       "      <td>{aldo_leopold}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aage_niels_bohr</td>\n",
       "      <td>{niels_bohr}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaron_burr</td>\n",
       "      <td>{aaron_burr_sr}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abaqa_khan</td>\n",
       "      <td>{hulagu_khan}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               child            parent  num_parents\n",
       "0     a_k_faezul_huq  {a_k_fazlul_huq}            1\n",
       "1  a_starker_leopold    {aldo_leopold}            1\n",
       "2    aage_niels_bohr      {niels_bohr}            1\n",
       "3         aaron_burr   {aaron_burr_sr}            1\n",
       "4         abaqa_khan     {hulagu_khan}            1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents_per_child = parents.groupby('child', as_index=False).agg(set)\n",
    "parents_per_child['num_parents'] = parents_per_child['parent'].apply(len)\n",
    "parents_per_child.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3b653b-fb16-46e9-b1dc-ba37981deee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_parents_df = parents_per_child[parents_per_child['num_parents']== 2]\n",
    "two_parents = dict()\n",
    "for i, row in two_parents_df.iterrows():\n",
    "    two_parents[row.child] = row.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d57bc20f-92b0-46b8-af61-d4efeeb99877",
   "metadata": {},
   "outputs": [],
   "source": [
    "siblings = dict()\n",
    "for child_i, parents_i in two_parents.items():\n",
    "    siblings[child_i] = set()\n",
    "    for child_j, parents_j in two_parents.items():\n",
    "        if child_i != child_j and parents_i == parents_j:\n",
    "            siblings[child_i].add(child_j)\n",
    "    if len(siblings[child_i]) == 0:\n",
    "        del siblings[child_i]\n",
    "    else:\n",
    "        siblings[child_i] = list(siblings[child_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634cd9c7-d2f5-45b5-843f-09d58f11883a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216384"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f'{data_dir}/resplit_with_sibs/siblings_via_two_shared_parents.json', 'w') as f:\n",
    "    f.write(json.dumps(siblings, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0146486a-dd8e-454d-a426-3606886cdf6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "triples_list = []\n",
    "for child, sibs in siblings.items():\n",
    "    for sib in sibs:\n",
    "        triples_list.append([child, 'sibling', sib])\n",
    "sib_triples = pd.DataFrame(triples_list, columns=['e1', 'rel', 'e2'])\n",
    "sib_triples.drop_duplicates(inplace=True, ignore_index=True) \n",
    "\n",
    "sib_triples.to_csv(f'{data_dir}/resplit_with_sibs/siblings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3caa422-6e76-495f-96ea-eb7f4e9a70bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{data_dir}/resplit/train.txt', sep='\\t', names=['e1', 'rel', 'e2'])\n",
    "valid = pd.read_csv(f'{data_dir}/resplit/valid.txt', sep='\\t', names=['e1', 'rel', 'e2'])\n",
    "test = pd.read_csv(f'{data_dir}/resplit/test.txt', sep='\\t', names=['e1', 'rel', 'e2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aee7243-b767-4174-9636-72cf48c5614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sib_train, sib_valid, sib_test = split_triples(sib_triples, fracs=[0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52dd48be-1f8f-4b13-8d71-228f0486a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, sib_train], axis=0, ignore_index=True)\n",
    "valid = pd.concat([valid, sib_valid], axis=0, ignore_index=True)\n",
    "test = pd.concat([test, sib_test], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a16625b4-e1db-4b16-8a0d-4010ed1da745",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(f'{data_dir}resplit_with_sibs/train.txt', sep='\\t', index=False, header=None)\n",
    "valid.to_csv(f'{data_dir}resplit_with_sibs/valid.txt', sep='\\t', index=False, header=None)\n",
    "test.to_csv(f'{data_dir}resplit_with_sibs/test.txt', sep='\\t', index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
